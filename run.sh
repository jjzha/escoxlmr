python3 src/run_mlm_xlmr.py --train_file resources/dummy.txt \
                            --line_by_line \
                            --output_dir xlm-test \
                            --model_type xlm-roberta-large \
                            --tokenizer_name xlm-roberta-large \
                            --per_device_train_batch_size 64 \
                            --gradient_accumulation_steps 128  \
                            --model_name_or_path xlm-roberta-large \
                            --do_train \
                            --max_steps 12500  \
                            --learning_rate 0.0005
